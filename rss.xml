<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title></title>
        <link>undefined</link>
        <description>undefined</description>
        <lastBuildDate>Wed, 10 Aug 2022 03:52:25 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>Joplin Pages Publisher</generator>
        <item>
            <title><![CDATA[Intrusion detection(Binary classification) with PCA and RandomForest]]></title>
            <guid>610a86a8963141b08eb7dd89769e4797</guid>
            <pubDate>Mon, 20 Jun 2022 03:46:04 GMT</pubDate>
            <content:encoded><![CDATA[<div><pre class="hljs"><code><span class="hljs-string">'''
Project: NGuard
Dataset: http://205.174.165.80/CICDataset/CIC-IDS-2017/Dataset/MachineLearningCSV.zip
'''</span>
</code></pre></div>
<div><pre class="hljs"><code>'<span class="hljs-symbol">\n</span>Project: NGuard<span class="hljs-symbol">\n</span>Dataset: http://205.174.165.80/CICDataset/CIC-IDS-2017/Dataset/MachineLearningCSV.zip<span class="hljs-symbol">\n</span>' </code></pre></div>
<p><strong>Extracting the parquet file which consist of network flows of Monday,Tuesday,Wednesday,Thursday and Friday</strong></p>
<div><pre class="hljs"><code><span class="hljs-keyword">from</span> google.colab <span class="hljs-keyword">import</span> drive
drive.mount(<span class="hljs-string">'/content/drive'</span>)


<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> glob
<span class="hljs-keyword">import</span> pathlib
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">from</span> joblib <span class="hljs-keyword">import</span> dump,load

<span class="hljs-keyword">def</span> <span class="hljs-title function_">extract_dataset</span>():
  <span class="hljs-string">'''
  Look for the merged parquet file in the cwd,
  if not found unzip the dataset.zip and return the
  cwd of the data.
  '''</span>
  file_name = pathlib.Path(<span class="hljs-string">"merged.parquet"</span>)
  <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> file_name.exists ():
    <span class="hljs-keyword">import</span> zipfile
    <span class="hljs-keyword">with</span> zipfile.ZipFile(os.getcwd()+<span class="hljs-string">"/drive/MyDrive/dataset.zip"</span>,<span class="hljs-string">"r"</span>) <span class="hljs-keyword">as</span> zip_ref:
      zip_ref.extractall()

  folder_path = os.getcwd() 
  <span class="hljs-keyword">return</span> folder_path  


<span class="hljs-keyword">def</span> <span class="hljs-title function_">read_as_dataframe</span>(<span class="hljs-params">master_file</span>):
  <span class="hljs-string">'''
  Look for the merged parquet file in the cwd,
  if not found merge the dataframes and return a single
  merged dataframe.
  '''</span>
  file_name = pathlib.Path(<span class="hljs-string">"merged.parquet"</span>)
  <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> file_name.exists ():
    df = pd.concat(master_file,ignore_index=<span class="hljs-literal">True</span>)
    df.to_parquet(<span class="hljs-string">'merged.parquet'</span>,index=<span class="hljs-literal">False</span>)
  <span class="hljs-keyword">else</span>:  
    df = pd.read_parquet(file_name,engine=<span class="hljs-string">'pyarrow'</span>)
  <span class="hljs-keyword">return</span> df
</code></pre></div>
<div><pre class="hljs"><code>Drive already mounted at /content/drive; <span class="hljs-keyword">to</span> attempt <span class="hljs-keyword">to</span> forcibly remount, call drive.mount(<span class="hljs-string">"/content/drive"</span>, <span class="hljs-attribute">force_remount</span>=<span class="hljs-literal">True</span>). </code></pre></div>
<p><strong>Extract the data from zip file</strong></p>
<div><pre class="hljs"><code><span class="hljs-comment"># returns the location of dataset</span>
dirpath = extract_dataset()
</code></pre></div>
<p><strong>Read parquet file as dataframe</strong></p>
<div><pre class="hljs"><code>mon = pd.read_parquet(<span class="hljs-string">f'<span class="hljs-subst">{dirpath}</span>/monday.parquet'</span>,engine=<span class="hljs-string">"pyarrow"</span>)
tues = pd.read_parquet(<span class="hljs-string">f'<span class="hljs-subst">{dirpath}</span>/tuesday.parquet'</span>,engine=<span class="hljs-string">"pyarrow"</span>)
wed =  pd.read_parquet(<span class="hljs-string">f'<span class="hljs-subst">{dirpath}</span>/wednesday.parquet'</span>,engine=<span class="hljs-string">"pyarrow"</span>)
thurs =  pd.concat([
                    pd.read_parquet(<span class="hljs-string">f'<span class="hljs-subst">{dirpath}</span>/thursday1.parquet'</span>,engine=<span class="hljs-string">"pyarrow"</span>),
                    pd.read_parquet(<span class="hljs-string">f'<span class="hljs-subst">{dirpath}</span>/thursday2.parquet'</span>,engine=<span class="hljs-string">"pyarrow"</span>),
                    ],ignore_index=<span class="hljs-literal">True</span>)
fri =  pd.concat([pd.read_parquet(<span class="hljs-string">f'<span class="hljs-subst">{dirpath}</span>/friday1.parquet'</span>,engine=<span class="hljs-string">"pyarrow"</span>),
                    pd.read_parquet(<span class="hljs-string">f'<span class="hljs-subst">{dirpath}</span>/friday2.parquet'</span>,engine=<span class="hljs-string">"pyarrow"</span>),
                    pd.read_parquet(<span class="hljs-string">f'<span class="hljs-subst">{dirpath}</span>/friday3.parquet'</span>,engine=<span class="hljs-string">"pyarrow"</span>),
                    ],ignore_index=<span class="hljs-literal">True</span>)

</code></pre></div>
<p><strong>Display the total numbers of data in each dataframe</strong></p>
<div><pre class="hljs"><code><span class="hljs-built_in">print</span>(<span class="hljs-string">'monday'</span>, mon[<span class="hljs-string">' Label'</span>].unique(),mon[<span class="hljs-string">' Label'</span>].count())
<span class="hljs-built_in">print</span>(<span class="hljs-string">'tuesday'</span>, tues[<span class="hljs-string">' Label'</span>].unique(),tues[<span class="hljs-string">' Label'</span>].count())
<span class="hljs-built_in">print</span>(<span class="hljs-string">'wednesday'</span>, wed[<span class="hljs-string">' Label'</span>].unique(),wed[<span class="hljs-string">' Label'</span>].count())
<span class="hljs-built_in">print</span>(<span class="hljs-string">'thursday'</span>, thurs[<span class="hljs-string">' Label'</span>].unique(),thurs[<span class="hljs-string">' Label'</span>].count())
<span class="hljs-built_in">print</span>(<span class="hljs-string">'friday'</span>, fri[<span class="hljs-string">' Label'</span>].unique(),fri[<span class="hljs-string">' Label'</span>].count())</code></pre></div>
<div><pre class="hljs"><code>monday [<span class="hljs-string">'BENIGN'</span>] <span class="hljs-number">529918</span>
tuesday [<span class="hljs-string">'BENIGN'</span> <span class="hljs-string">'FTP-Patator'</span> <span class="hljs-string">'SSH-Patator'</span>] <span class="hljs-number">445909</span>
wednesday [<span class="hljs-string">'BENIGN'</span> <span class="hljs-string">'DoS slowloris'</span> <span class="hljs-string">'DoS Slowhttptest'</span> <span class="hljs-string">'DoS Hulk'</span> <span class="hljs-string">'DoS GoldenEye'</span>
 <span class="hljs-string">'Heartbleed'</span>] <span class="hljs-number">692703</span>
thursday [<span class="hljs-string">'BENIGN'</span> <span class="hljs-string">'Web Attack � Brute Force'</span> <span class="hljs-string">'Web Attack � XSS'</span>
 <span class="hljs-string">'Web Attack � Sql Injection'</span> <span class="hljs-string">'Infiltration'</span>] <span class="hljs-number">458968</span>
friday [<span class="hljs-string">'BENIGN'</span> <span class="hljs-string">'Bot'</span> <span class="hljs-string">'PortScan'</span> <span class="hljs-string">'DDoS'</span>] <span class="hljs-number">703245</span> </code></pre></div>
<p>We can see that monday has only benign data, and other days have mix of attack and benign labels. We can exclude monday data and form a combined dataset of other days.</p>
<div><pre class="hljs"><code>merged  = read_as_dataframe([tues.drop_duplicates(),wed.drop_duplicates(),thurs.drop_duplicates(),fri.drop_duplicates()])

<span class="hljs-built_in">print</span>(merged[<span class="hljs-string">' Label'</span>].value_counts())
</code></pre></div>
<div><pre class="hljs"><code><span class="hljs-attribute">BENIGN</span>                        <span class="hljs-number">1635861</span>
<span class="hljs-attribute">DoS</span> Hulk                       <span class="hljs-number">172849</span>
<span class="hljs-attribute">DDoS</span>                           <span class="hljs-number">128016</span>
<span class="hljs-attribute">PortScan</span>                        <span class="hljs-number">90819</span>
<span class="hljs-attribute">DoS</span> GoldenEye                   <span class="hljs-number">10286</span>
<span class="hljs-attribute">FTP</span>-Patator                      <span class="hljs-number">5933</span>
<span class="hljs-attribute">DoS</span> slowloris                    <span class="hljs-number">5385</span>
<span class="hljs-attribute">DoS</span> Slowhttptest                 <span class="hljs-number">5228</span>
<span class="hljs-attribute">SSH</span>-Patator                      <span class="hljs-number">3219</span>
<span class="hljs-attribute">Bot</span>                              <span class="hljs-number">1953</span>
<span class="hljs-attribute">Web</span> Attack � Brute Force         <span class="hljs-number">1470</span>
<span class="hljs-attribute">Web</span> Attack � XSS                  <span class="hljs-number">652</span>
<span class="hljs-attribute">Infiltration</span>                       <span class="hljs-number">36</span>
<span class="hljs-attribute">Web</span> Attack � Sql Injection         <span class="hljs-number">21</span>
<span class="hljs-attribute">Heartbleed</span>                         <span class="hljs-number">11</span>
<span class="hljs-attribute">Name</span>:  Label, dtype: int64 </code></pre></div>
<p>From above we can see, in the total dataset, infiltration, web attack sql injection and heartbleed has comparatively less amount of data</p>
<p>We will ignore them from training data but will use for testing purpose since they would be a type of unseen data for the model</p>
<div><pre class="hljs"><code>infil = merged.loc[merged[<span class="hljs-string">' Label'</span>] == <span class="hljs-string">'Infiltration'</span>]
sqli = merged.loc[merged[<span class="hljs-string">' Label'</span>]== <span class="hljs-string">'Web Attack � Sql Injection'</span>]
hb = merged.loc[merged[<span class="hljs-string">' Label'</span>]== <span class="hljs-string">'Heartbleed'</span>]
merged.drop(infil.index,inplace=<span class="hljs-literal">True</span>)
merged.drop(sqli.index,inplace=<span class="hljs-literal">True</span>)
merged.drop(hb.index,inplace=<span class="hljs-literal">True</span>)
new_test = pd.concat([infil,sqli,hb],ignore_index=<span class="hljs-literal">True</span>)
<span class="hljs-keyword">del</span> infil
<span class="hljs-keyword">del</span> sqli
<span class="hljs-keyword">del</span> hb</code></pre></div>
<p><strong>Statistics of merged dataframe</strong></p>
<div><pre class="hljs"><code><span class="hljs-built_in">print</span>(merged.columns)
<span class="hljs-built_in">print</span>(merged.shape)</code></pre></div>
<div><pre class="hljs"><code>Index([<span class="hljs-string">' Destination Port'</span>, <span class="hljs-string">' Flow Duration'</span>, <span class="hljs-string">' Total Fwd Packets'</span>,
       <span class="hljs-string">' Total Backward Packets'</span>, <span class="hljs-string">'Total Length of Fwd Packets'</span>,
       <span class="hljs-string">' Total Length of Bwd Packets'</span>, <span class="hljs-string">' Fwd Packet Length Max'</span>,
       <span class="hljs-string">' Fwd Packet Length Min'</span>, <span class="hljs-string">' Fwd Packet Length Mean'</span>,
       <span class="hljs-string">' Fwd Packet Length Std'</span>, <span class="hljs-string">'Bwd Packet Length Max'</span>,
       <span class="hljs-string">' Bwd Packet Length Min'</span>, <span class="hljs-string">' Bwd Packet Length Mean'</span>,
       <span class="hljs-string">' Bwd Packet Length Std'</span>, <span class="hljs-string">'Flow Bytes/s'</span>, <span class="hljs-string">' Flow Packets/s'</span>,
       <span class="hljs-string">' Flow IAT Mean'</span>, <span class="hljs-string">' Flow IAT Std'</span>, <span class="hljs-string">' Flow IAT Max'</span>, <span class="hljs-string">' Flow IAT Min'</span>,
       <span class="hljs-string">'Fwd IAT Total'</span>, <span class="hljs-string">' Fwd IAT Mean'</span>, <span class="hljs-string">' Fwd IAT Std'</span>, <span class="hljs-string">' Fwd IAT Max'</span>,
       <span class="hljs-string">' Fwd IAT Min'</span>, <span class="hljs-string">'Bwd IAT Total'</span>, <span class="hljs-string">' Bwd IAT Mean'</span>, <span class="hljs-string">' Bwd IAT Std'</span>,
       <span class="hljs-string">' Bwd IAT Max'</span>, <span class="hljs-string">' Bwd IAT Min'</span>, <span class="hljs-string">'Fwd PSH Flags'</span>, <span class="hljs-string">' Bwd PSH Flags'</span>,
       <span class="hljs-string">' Fwd URG Flags'</span>, <span class="hljs-string">' Bwd URG Flags'</span>, <span class="hljs-string">' Fwd Header Length'</span>,
       <span class="hljs-string">' Bwd Header Length'</span>, <span class="hljs-string">'Fwd Packets/s'</span>, <span class="hljs-string">' Bwd Packets/s'</span>,
       <span class="hljs-string">' Min Packet Length'</span>, <span class="hljs-string">' Max Packet Length'</span>, <span class="hljs-string">' Packet Length Mean'</span>,
       <span class="hljs-string">' Packet Length Std'</span>, <span class="hljs-string">' Packet Length Variance'</span>, <span class="hljs-string">'FIN Flag Count'</span>,
       <span class="hljs-string">' SYN Flag Count'</span>, <span class="hljs-string">' RST Flag Count'</span>, <span class="hljs-string">' PSH Flag Count'</span>,
       <span class="hljs-string">' ACK Flag Count'</span>, <span class="hljs-string">' URG Flag Count'</span>, <span class="hljs-string">' CWE Flag Count'</span>,
       <span class="hljs-string">' ECE Flag Count'</span>, <span class="hljs-string">' Down/Up Ratio'</span>, <span class="hljs-string">' Average Packet Size'</span>,
       <span class="hljs-string">' Avg Fwd Segment Size'</span>, <span class="hljs-string">' Avg Bwd Segment Size'</span>,
       <span class="hljs-string">' Fwd Header Length.1'</span>, <span class="hljs-string">'Fwd Avg Bytes/Bulk'</span>, <span class="hljs-string">' Fwd Avg Packets/Bulk'</span>,
       <span class="hljs-string">' Fwd Avg Bulk Rate'</span>, <span class="hljs-string">' Bwd Avg Bytes/Bulk'</span>, <span class="hljs-string">' Bwd Avg Packets/Bulk'</span>,
       <span class="hljs-string">'Bwd Avg Bulk Rate'</span>, <span class="hljs-string">'Subflow Fwd Packets'</span>, <span class="hljs-string">' Subflow Fwd Bytes'</span>,
       <span class="hljs-string">' Subflow Bwd Packets'</span>, <span class="hljs-string">' Subflow Bwd Bytes'</span>, <span class="hljs-string">'Init_Win_bytes_forward'</span>,
       <span class="hljs-string">' Init_Win_bytes_backward'</span>, <span class="hljs-string">' act_data_pkt_fwd'</span>,
       <span class="hljs-string">' min_seg_size_forward'</span>, <span class="hljs-string">'Active Mean'</span>, <span class="hljs-string">' Active Std'</span>, <span class="hljs-string">' Active Max'</span>,
       <span class="hljs-string">' Active Min'</span>, <span class="hljs-string">'Idle Mean'</span>, <span class="hljs-string">' Idle Std'</span>, <span class="hljs-string">' Idle Max'</span>, <span class="hljs-string">' Idle Min'</span>,
       <span class="hljs-string">' Label'</span>],
      <span class="hljs-attribute">dtype</span>=<span class="hljs-string">'object'</span>)
(2061671, 79) </code></pre></div>
<h5 id="the-intrusion-detection-problem-can-be-achieved-as-either-anomaly-based-approach-or-even-as-supervised-binary-classification-approach">The intrusion detection problem can be achieved as either anomaly based approach or even as supervised binary classification approach</h5>
<hr />
<p>We will proceed with the later one, converting all attack class lables as single class ‘anomaly’.</p>
<p>Using such method we will be left with 2 classes: Benign and Anomaly(Intrusion)</p>
<div><pre class="hljs"><code>labels = merged[<span class="hljs-string">' Label'</span>].copy()
<span class="hljs-built_in">print</span>(labels.unique())
labels[labels != <span class="hljs-string">'BENIGN'</span>]=<span class="hljs-string">'ANOMALOUS'</span>
<span class="hljs-built_in">print</span>(labels.unique())

val = labels.value_counts()
<span class="hljs-built_in">print</span>(<span class="hljs-string">'benign:'</span>,(val[<span class="hljs-string">'BENIGN'</span>]/(val[<span class="hljs-string">'BENIGN'</span>]+val[<span class="hljs-string">'ANOMALOUS'</span>]))*<span class="hljs-number">100</span> )
<span class="hljs-built_in">print</span>(<span class="hljs-string">'anomalous:'</span>,(val[<span class="hljs-string">'ANOMALOUS'</span>]/(val[<span class="hljs-string">'BENIGN'</span>]+val[<span class="hljs-string">'ANOMALOUS'</span>])*<span class="hljs-number">100</span> ))</code></pre></div>
<div><pre class="hljs"><code>[<span class="hljs-string">'BENIGN'</span> <span class="hljs-string">'FTP-Patator'</span> <span class="hljs-string">'SSH-Patator'</span> <span class="hljs-string">'DoS slowloris'</span> <span class="hljs-string">'DoS Slowhttptest'</span>
 <span class="hljs-string">'DoS Hulk'</span> <span class="hljs-string">'DoS GoldenEye'</span> <span class="hljs-string">'Web Attack � Brute Force'</span> <span class="hljs-string">'Web Attack � XSS'</span>
 <span class="hljs-string">'Bot'</span> <span class="hljs-string">'PortScan'</span> <span class="hljs-string">'DDoS'</span>]
[<span class="hljs-string">'BENIGN'</span> <span class="hljs-string">'ANOMALOUS'</span>]
benign: <span class="hljs-number">79.34636515719531</span>
anomalous: <span class="hljs-number">20.653634842804696</span> </code></pre></div>
<p>From above we see the dataset is pretty unbalanced for supervised learning.
Such imbalance can cause overfitting to a perticular class especially benign.</p>
<p><strong>Data processing</strong></p>
<p>Before splitting the dataset into train and test, there are some considirations to be taken.</p>
<hr />
<p>Frome the dataset these would be dropped:
<em><strong>Destination port</strong></em>; reason no significance since services are run on any port by the host, example: ssh service can be run for any port, so port 22 attack dont necessarily have to trigger attack.</p>
<div><pre class="hljs"><code>merged.replace([np.inf, -np.inf], np.nan, inplace=<span class="hljs-literal">True</span>)
merged[merged.columns[merged.isna().<span class="hljs-built_in">any</span>()]].columns</code></pre></div>
<div><pre class="hljs"><code><span class="hljs-function"><span class="hljs-title">Index</span><span class="hljs-params">([<span class="hljs-string">'Flow Bytes/s'</span>, <span class="hljs-string">' Flow Packets/s'</span>], dtype=<span class="hljs-string">'object'</span>)</span></span> </code></pre></div>
<div><pre class="hljs"><code>merged[merged.columns[merged.isnull().<span class="hljs-built_in">any</span>()]].columns
</code></pre></div>
<div><pre class="hljs"><code><span class="hljs-function"><span class="hljs-title">Index</span><span class="hljs-params">([<span class="hljs-string">'Flow Bytes/s'</span>, <span class="hljs-string">' Flow Packets/s'</span>], dtype=<span class="hljs-string">'object'</span>)</span></span> </code></pre></div>
<p>From above we can see [‘Flow Bytes/s’, ’ Flow Packets/s’] have nan or null or infinite vaues, we proceed cleaning by dropping these columns too. Further in the dataset ’ Fwd Header Length.1’ is redundent with the ’ Fwd Header Length’ column.</p>
<p>Dropping columns from the dataset and separating X and Y as input matrix and target vector and further denoting Benign as 1 and Anomalous as -1 we obtain as following</p>
<div><pre class="hljs"><code>merged.drop([<span class="hljs-string">' Destination Port'</span>,<span class="hljs-string">'Flow Bytes/s'</span>,<span class="hljs-string">' Flow Packets/s'</span>,<span class="hljs-string">' Fwd Header Length.1'</span>],inplace=<span class="hljs-literal">True</span>,axis=<span class="hljs-number">1</span>)
merged.columns = [<span class="hljs-string">'Flow Duration'</span>, <span class="hljs-string">'Tot Fwd Pkts'</span>, <span class="hljs-string">'Tot Bwd Pkts'</span>, <span class="hljs-string">'TotLen Fwd Pkts'</span>,
       <span class="hljs-string">'TotLen Bwd Pkts'</span>, <span class="hljs-string">'Fwd Pkt Len Max'</span>, <span class="hljs-string">'Fwd Pkt Len Min'</span>,
       <span class="hljs-string">'Fwd Pkt Len Mean'</span>, <span class="hljs-string">'Fwd Pkt Len Std'</span>, <span class="hljs-string">'Bwd Pkt Len Max'</span>,
       <span class="hljs-string">'Bwd Pkt Len Min'</span>, <span class="hljs-string">'Bwd Pkt Len Mean'</span>, <span class="hljs-string">'Bwd Pkt Len Std'</span>,
       <span class="hljs-string">'Flow IAT Mean'</span>, <span class="hljs-string">'Flow IAT Std'</span>, <span class="hljs-string">'Flow IAT Max'</span>, <span class="hljs-string">'Flow IAT Min'</span>,
       <span class="hljs-string">'Fwd IAT Tot'</span>, <span class="hljs-string">'Fwd IAT Mean'</span>, <span class="hljs-string">'Fwd IAT Std'</span>, <span class="hljs-string">'Fwd IAT Max'</span>,
       <span class="hljs-string">'Fwd IAT Min'</span>, <span class="hljs-string">'Bwd IAT Tot'</span>, <span class="hljs-string">'Bwd IAT Mean'</span>, <span class="hljs-string">'Bwd IAT Std'</span>,
       <span class="hljs-string">'Bwd IAT Max'</span>, <span class="hljs-string">'Bwd IAT Min'</span>, <span class="hljs-string">'Fwd PSH Flags'</span>, <span class="hljs-string">'Bwd PSH Flags'</span>,
       <span class="hljs-string">'Fwd URG Flags'</span>, <span class="hljs-string">'Bwd URG Flags'</span>, <span class="hljs-string">'Fwd Header Len'</span>, <span class="hljs-string">'Bwd Header Len'</span>,
       <span class="hljs-string">'Fwd Pkts/s'</span>, <span class="hljs-string">'Bwd Pkts/s'</span>, <span class="hljs-string">'Pkt Len Min'</span>, <span class="hljs-string">'Pkt Len Max'</span>,
       <span class="hljs-string">'Pkt Len Mean'</span>, <span class="hljs-string">'Pkt Len Std'</span>, <span class="hljs-string">'Pkt Len Var'</span>, <span class="hljs-string">'FIN Flag Cnt'</span>,
       <span class="hljs-string">'SYN Flag Cnt'</span>, <span class="hljs-string">'RST Flag Cnt'</span>, <span class="hljs-string">'PSH Flag Cnt'</span>, <span class="hljs-string">'ACK Flag Cnt'</span>,
       <span class="hljs-string">'URG Flag Cnt'</span>, <span class="hljs-string">'CWE Flag Count'</span>, <span class="hljs-string">'ECE Flag Cnt'</span>, <span class="hljs-string">'Down/Up Ratio'</span>,
       <span class="hljs-string">'Pkt Size Avg'</span>, <span class="hljs-string">'Fwd Seg Size Avg'</span>, <span class="hljs-string">'Bwd Seg Size Avg'</span>,
       <span class="hljs-string">'Fwd Byts/b Avg'</span>, <span class="hljs-string">'Fwd Pkts/b Avg'</span>, <span class="hljs-string">'Fwd Blk Rate Avg'</span>,
       <span class="hljs-string">'Bwd Byts/b Avg'</span>, <span class="hljs-string">'Bwd Pkts/b Avg'</span>, <span class="hljs-string">'Bwd Blk Rate Avg'</span>,
       <span class="hljs-string">'Subflow Fwd Pkts'</span>, <span class="hljs-string">'Subflow Fwd Byts'</span>, <span class="hljs-string">'Subflow Bwd Pkts'</span>,
       <span class="hljs-string">'Subflow Bwd Byts'</span>, <span class="hljs-string">'Init Fwd Win Byts'</span>, <span class="hljs-string">'Init Bwd Win Byts'</span>,
       <span class="hljs-string">'Fwd Act Data Pkts'</span>, <span class="hljs-string">'Fwd Seg Size Min'</span>, <span class="hljs-string">'Active Mean'</span>, <span class="hljs-string">'Active Std'</span>,
       <span class="hljs-string">'Active Max'</span>, <span class="hljs-string">'Active Min'</span>, <span class="hljs-string">'Idle Mean'</span>, <span class="hljs-string">'Idle Std'</span>, <span class="hljs-string">'Idle Max'</span>,
       <span class="hljs-string">'Idle Min'</span>, <span class="hljs-string">'Label'</span>]
X = merged.drop([<span class="hljs-string">'Label'</span>],axis=<span class="hljs-number">1</span>)
merged[merged[<span class="hljs-string">'Label'</span>] != <span class="hljs-string">'BENIGN'</span>]= <span class="hljs-number">0</span>
merged[merged[<span class="hljs-string">'Label'</span>] != <span class="hljs-number">0</span>]= <span class="hljs-number">1</span>
y = merged[<span class="hljs-string">'Label'</span>].copy()</code></pre></div>
<p><strong>Training Phase</strong></p>
<p>Since the dataset is quite large it will be irrelavant to train with all about 28 lakh of data. So, for splitting into train test, we take about only 10 percent of it and rest for testing. We use stratify to maintain the propotion of binary class for now.</p>
<div><pre class="hljs"><code><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,y,stratify=y,train_size=<span class="hljs-number">0.10</span>)</code></pre></div>
<div><pre class="hljs"><code><span class="hljs-built_in">print</span>(<span class="hljs-string">"X_train.shape"</span>,X_train.shape)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"X_test.shape"</span>,X_test.shape)</code></pre></div>
<div><pre class="hljs"><code><span class="hljs-attribute">X_train</span>.shape (<span class="hljs-number">206167</span>, <span class="hljs-number">74</span>)
<span class="hljs-attribute">X_test</span>.shape (<span class="hljs-number">1855504</span>, <span class="hljs-number">74</span>) </code></pre></div>
<p><strong>Dimentionality Reduction with PCA</strong></p>
<p>Before applying Principal Component Analysis, we need to scale the input matrix.
We do that by using standar scaler. refer to:<a title="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html</a></p>
<p>As refering to ‘<a title="https://doi.org/10.3390/electronics8030322" href="https://doi.org/10.3390/electronics8030322">https://doi.org/10.3390/electronics8030322</a>’ paper,
we try to reduce 74 features into 10 principal components.</p>
<div><pre class="hljs"><code><span class="hljs-built_in">print</span>(<span class="hljs-string">"finite negative value"</span>,(X &lt; <span class="hljs-number">0</span>).values.<span class="hljs-built_in">any</span>())
<span class="hljs-built_in">print</span>(<span class="hljs-string">"finite positive value"</span>,(X &gt; <span class="hljs-number">0</span>).values.<span class="hljs-built_in">any</span>())</code></pre></div>
<div><pre class="hljs"><code><span class="hljs-built_in">finite</span> negative value <span class="hljs-literal">True</span>
<span class="hljs-built_in">finite</span> positive value <span class="hljs-literal">True</span> </code></pre></div>
<div><pre class="hljs"><code><span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler


ss = StandardScaler()
X_Scale = ss.fit_transform(X_train.values)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"X_scale shape:"</span>,X_Scale.shape)
dump(ss, <span class="hljs-string">'bscaler.joblib'</span>) 


pca = PCA(n_components=<span class="hljs-number">10</span>)
principal_components = pca.fit_transform(X_Scale)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"X_pca shape:"</span>,principal_components.shape)
dump(pca, <span class="hljs-string">'bpca.joblib'</span>) 
</code></pre></div>
<div><pre class="hljs"><code>X_scale shape: <span class="hljs-comment">(206167, 74)</span>
X_pca shape: <span class="hljs-comment">(206167, 10)</span>





[<span class="hljs-string">'bpca.joblib'</span>] </code></pre></div>
<div><pre class="hljs"><code>pca.explained_variance_ratio_</code></pre></div>
<div><pre class="hljs"><code><span class="hljs-attribute">array</span>([<span class="hljs-number">0</span>.<span class="hljs-number">23016039</span>, <span class="hljs-number">0</span>.<span class="hljs-number">14102824</span>, <span class="hljs-number">0</span>.<span class="hljs-number">08945196</span>, <span class="hljs-number">0</span>.<span class="hljs-number">0645161</span> , <span class="hljs-number">0</span>.<span class="hljs-number">04670917</span>,
       <span class="hljs-attribute">0</span>.<span class="hljs-number">04254841</span>, <span class="hljs-number">0</span>.<span class="hljs-number">03680265</span>, <span class="hljs-number">0</span>.<span class="hljs-number">03450822</span>, <span class="hljs-number">0</span>.<span class="hljs-number">03041049</span>, <span class="hljs-number">0</span>.<span class="hljs-number">03030438</span>]) </code></pre></div>
<p>Still the training data is imbalanced as nearly on a 80:20 ratio
we apply SMOTE to balance the training dataset by increasing the number of minor class data by over sampling.</p>
<p>Refer to: <a title="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html" href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html">https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html</a></p>
<div><pre class="hljs"><code><span class="hljs-keyword">from</span> imblearn.over_sampling <span class="hljs-keyword">import</span> SMOTE

sm = SMOTE(random_state=<span class="hljs-number">2</span>)
X,Y = sm.fit_resample(principal_components,Y_train.values.astype(<span class="hljs-string">'int'</span>))

<span class="hljs-built_in">print</span>(X.shape)
<span class="hljs-built_in">print</span>(y.shape)</code></pre></div>
<div><pre class="hljs"><code>(<span class="hljs-number">327172</span>, <span class="hljs-number">10</span>)
(<span class="hljs-number">2061671</span>,) </code></pre></div>
<p><strong>Training with Random Forest classifier</strong></p>
<p>Refer to: <a title="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html</a></p>
<p>Here, random forest an ensemble technique is used to train a model.
The forest keeps on splitting until pure leaves are found.
Here, total ensemblers used are 100, with random state =10.</p>
<div><pre class="hljs"><code><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier
clf = RandomForestClassifier(random_state=<span class="hljs-number">0</span>,n_jobs=-<span class="hljs-number">1</span>)
</code></pre></div>
<div><pre class="hljs"><code><span class="hljs-keyword">from</span> sklearn.experimental <span class="hljs-keyword">import</span> enable_halving_search_cv  
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> HalvingGridSearchCV
param_grid = {<span class="hljs-string">"max_depth"</span>: [<span class="hljs-number">10</span>, <span class="hljs-literal">None</span>],
              <span class="hljs-string">"min_samples_split"</span>: [<span class="hljs-number">5</span>, <span class="hljs-number">10</span>]}
search = HalvingGridSearchCV(clf, param_grid, resource=<span class="hljs-string">'n_estimators'</span>,
                              max_resources=<span class="hljs-number">10</span>,random_state=<span class="hljs-number">0</span>).fit(X, Y)
<span class="hljs-built_in">print</span>(search.best_params_ )</code></pre></div>
<div><pre class="hljs"><code>{<span class="hljs-string">'max_depth'</span>: <span class="hljs-literal">None</span>, <span class="hljs-string">'min_samples_split'</span>: <span class="hljs-number">5</span>, <span class="hljs-string">'n_estimators'</span>: <span class="hljs-number">9</span>} </code></pre></div>
<div><pre class="hljs"><code><span class="hljs-comment"># search.best_params_['n_estimators']=50</span>
clf = RandomForestClassifier(random_state=<span class="hljs-number">10</span>,n_jobs=-<span class="hljs-number">1</span>,**search.best_params_)
clf.fit(X,Y)</code></pre></div>
<div><pre class="hljs"><code>RandomForestClassifier(<span class="hljs-attribute">min_samples_split</span>=5, <span class="hljs-attribute">n_estimators</span>=9, <span class="hljs-attribute">n_jobs</span>=-1,
                       <span class="hljs-attribute">random_state</span>=10) </code></pre></div>
<div><pre class="hljs"><code>dump(clf, <span class="hljs-string">'binary.joblib'</span>) </code></pre></div>
<div><pre class="hljs"><code>[<span class="hljs-symbol">'binary.joblib</span>'] </code></pre></div>
<div><pre class="hljs"><code>Y_predicted = clf.predict(pca.transform(ss.transform(X_test.values)))</code></pre></div>
<p><strong>Verifying</strong></p>
<div><pre class="hljs"><code><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_performance</span>(<span class="hljs-params">y_actual,y_predicted</span>):
    <span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> f1_score
    <span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix,ConfusionMatrixDisplay
    <span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> precision_recall_curve, precision_score
    <span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> recall_score
    <span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> average_precision_score
    <span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> roc_curve, auc, classification_report



    score = f1_score(y_actual,y_predicted,average=<span class="hljs-string">'micro'</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'F1 Score: %.3f'</span> % score)

    cmatrix = confusion_matrix(y_actual,y_predicted,labels=[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>])
    cm_obj = ConfusionMatrixDisplay(cmatrix,display_labels=[<span class="hljs-number">1</span>,<span class="hljs-number">0</span>])
    cm_obj.plot()
    cm_obj.ax_.<span class="hljs-built_in">set</span>(
                    title=<span class="hljs-string">'Sklearn Confusion Matrix for Benign and Intrusions'</span>, 
                    xlabel=<span class="hljs-string">'Predicted Class'</span>, 
                    ylabel=<span class="hljs-string">'True Class'</span>)



    <span class="hljs-built_in">print</span>(<span class="hljs-string">'Precison'</span>,precision_score(y_actual, y_predicted, average=<span class="hljs-string">'macro'</span>))
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'Recall'</span>,recall_score(y_actual, y_predicted, average=<span class="hljs-string">'macro'</span>))
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'Misclassification'</span>,(cmatrix[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]+cmatrix[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>])/(cmatrix[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]+cmatrix[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]+cmatrix[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>]+cmatrix[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>]))
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'\n'</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'Accuracy'</span>,(cmatrix[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]+cmatrix[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>])/(cmatrix[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>]+cmatrix[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]+cmatrix[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>]+cmatrix[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>]))
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'FPR(A classicifed as B)'</span>,(cmatrix[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>])/(cmatrix[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>]+cmatrix[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>]))

    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_actual, y_predicted)
    roc_auc = auc(false_positive_rate, true_positive_rate)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'roc auc'</span>,roc_auc)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">"Classification report:"</span> <span class="hljs-string">"\n"</span>,classification_report(y_actual,y_predicted))
</code></pre></div>
<div><pre class="hljs"><code>test_performance(y_actual=Y_test.astype(<span class="hljs-string">'int'</span>),y_predicted=Y_predicted)</code></pre></div>
<div><pre class="hljs"><code><span class="hljs-attribute">F1</span> Score: <span class="hljs-number">0</span>.<span class="hljs-number">990</span>
<span class="hljs-attribute">Precison</span> <span class="hljs-number">0</span>.<span class="hljs-number">9879654453757049</span>
<span class="hljs-attribute">Recall</span> <span class="hljs-number">0</span>.<span class="hljs-number">9802614457684058</span>
<span class="hljs-attribute">Misclassification</span> <span class="hljs-number">0</span>.<span class="hljs-number">010370767187782941</span>


<span class="hljs-attribute">Accuracy</span> <span class="hljs-number">0</span>.<span class="hljs-number">989629232812217</span>
<span class="hljs-attribute">FPR</span>(A classicifed as B) <span class="hljs-number">0</span>.<span class="hljs-number">03569928163056554</span>
<span class="hljs-attribute">roc</span> auc <span class="hljs-number">0</span>.<span class="hljs-number">9802614457684058</span>
<span class="hljs-attribute">Classification</span> report:
               <span class="hljs-attribute">precision</span>    recall  f1-score   support

           <span class="hljs-attribute">0</span>       <span class="hljs-number">0</span>.<span class="hljs-number">99</span>      <span class="hljs-number">0</span>.<span class="hljs-number">96</span>      <span class="hljs-number">0</span>.<span class="hljs-number">97</span>    <span class="hljs-number">383229</span>
           <span class="hljs-attribute">1</span>       <span class="hljs-number">0</span>.<span class="hljs-number">99</span>      <span class="hljs-number">1</span>.<span class="hljs-number">00</span>      <span class="hljs-number">0</span>.<span class="hljs-number">99</span>   <span class="hljs-number">1472275</span>

    <span class="hljs-attribute">accuracy</span>                           <span class="hljs-number">0</span>.<span class="hljs-number">99</span>   <span class="hljs-number">1855504</span>
   <span class="hljs-attribute">macro</span> avg       <span class="hljs-number">0</span>.<span class="hljs-number">99</span>      <span class="hljs-number">0</span>.<span class="hljs-number">98</span>      <span class="hljs-number">0</span>.<span class="hljs-number">98</span>   <span class="hljs-number">1855504</span>
<span class="hljs-attribute">weighted</span> avg       <span class="hljs-number">0</span>.<span class="hljs-number">99</span>      <span class="hljs-number">0</span>.<span class="hljs-number">99</span>      <span class="hljs-number">0</span>.<span class="hljs-number">99</span>   <span class="hljs-number">1855504</span> </code></pre></div>
<p><img src="/_resources/db3900ed774e493fba77e5a9ea340694.png" /></p>
<p><strong>Verifying with new_test</strong></p>
<div><pre class="hljs"><code>new_test.drop([<span class="hljs-string">' Destination Port'</span>,<span class="hljs-string">'Flow Bytes/s'</span>,<span class="hljs-string">' Flow Packets/s'</span>,<span class="hljs-string">' Fwd Header Length.1'</span>],inplace=<span class="hljs-literal">True</span>,axis=<span class="hljs-number">1</span>)
new_test.columns = [<span class="hljs-string">'Flow Duration'</span>, <span class="hljs-string">'Tot Fwd Pkts'</span>, <span class="hljs-string">'Tot Bwd Pkts'</span>, <span class="hljs-string">'TotLen Fwd Pkts'</span>,
       <span class="hljs-string">'TotLen Bwd Pkts'</span>, <span class="hljs-string">'Fwd Pkt Len Max'</span>, <span class="hljs-string">'Fwd Pkt Len Min'</span>,
       <span class="hljs-string">'Fwd Pkt Len Mean'</span>, <span class="hljs-string">'Fwd Pkt Len Std'</span>, <span class="hljs-string">'Bwd Pkt Len Max'</span>,
       <span class="hljs-string">'Bwd Pkt Len Min'</span>, <span class="hljs-string">'Bwd Pkt Len Mean'</span>, <span class="hljs-string">'Bwd Pkt Len Std'</span>,
       <span class="hljs-string">'Flow IAT Mean'</span>, <span class="hljs-string">'Flow IAT Std'</span>, <span class="hljs-string">'Flow IAT Max'</span>, <span class="hljs-string">'Flow IAT Min'</span>,
       <span class="hljs-string">'Fwd IAT Tot'</span>, <span class="hljs-string">'Fwd IAT Mean'</span>, <span class="hljs-string">'Fwd IAT Std'</span>, <span class="hljs-string">'Fwd IAT Max'</span>,
       <span class="hljs-string">'Fwd IAT Min'</span>, <span class="hljs-string">'Bwd IAT Tot'</span>, <span class="hljs-string">'Bwd IAT Mean'</span>, <span class="hljs-string">'Bwd IAT Std'</span>,
       <span class="hljs-string">'Bwd IAT Max'</span>, <span class="hljs-string">'Bwd IAT Min'</span>, <span class="hljs-string">'Fwd PSH Flags'</span>, <span class="hljs-string">'Bwd PSH Flags'</span>,
       <span class="hljs-string">'Fwd URG Flags'</span>, <span class="hljs-string">'Bwd URG Flags'</span>, <span class="hljs-string">'Fwd Header Len'</span>, <span class="hljs-string">'Bwd Header Len'</span>,
       <span class="hljs-string">'Fwd Pkts/s'</span>, <span class="hljs-string">'Bwd Pkts/s'</span>, <span class="hljs-string">'Pkt Len Min'</span>, <span class="hljs-string">'Pkt Len Max'</span>,
       <span class="hljs-string">'Pkt Len Mean'</span>, <span class="hljs-string">'Pkt Len Std'</span>, <span class="hljs-string">'Pkt Len Var'</span>, <span class="hljs-string">'FIN Flag Cnt'</span>,
       <span class="hljs-string">'SYN Flag Cnt'</span>, <span class="hljs-string">'RST Flag Cnt'</span>, <span class="hljs-string">'PSH Flag Cnt'</span>, <span class="hljs-string">'ACK Flag Cnt'</span>,
       <span class="hljs-string">'URG Flag Cnt'</span>, <span class="hljs-string">'CWE Flag Count'</span>, <span class="hljs-string">'ECE Flag Cnt'</span>, <span class="hljs-string">'Down/Up Ratio'</span>,
       <span class="hljs-string">'Pkt Size Avg'</span>, <span class="hljs-string">'Fwd Seg Size Avg'</span>, <span class="hljs-string">'Bwd Seg Size Avg'</span>,
       <span class="hljs-string">'Fwd Byts/b Avg'</span>, <span class="hljs-string">'Fwd Pkts/b Avg'</span>, <span class="hljs-string">'Fwd Blk Rate Avg'</span>,
       <span class="hljs-string">'Bwd Byts/b Avg'</span>, <span class="hljs-string">'Bwd Pkts/b Avg'</span>, <span class="hljs-string">'Bwd Blk Rate Avg'</span>,
       <span class="hljs-string">'Subflow Fwd Pkts'</span>, <span class="hljs-string">'Subflow Fwd Byts'</span>, <span class="hljs-string">'Subflow Bwd Pkts'</span>,
       <span class="hljs-string">'Subflow Bwd Byts'</span>, <span class="hljs-string">'Init Fwd Win Byts'</span>, <span class="hljs-string">'Init Bwd Win Byts'</span>,
       <span class="hljs-string">'Fwd Act Data Pkts'</span>, <span class="hljs-string">'Fwd Seg Size Min'</span>, <span class="hljs-string">'Active Mean'</span>, <span class="hljs-string">'Active Std'</span>,
       <span class="hljs-string">'Active Max'</span>, <span class="hljs-string">'Active Min'</span>, <span class="hljs-string">'Idle Mean'</span>, <span class="hljs-string">'Idle Std'</span>, <span class="hljs-string">'Idle Max'</span>,
       <span class="hljs-string">'Idle Min'</span>, <span class="hljs-string">'Label'</span>]
xx = new_test.drop([<span class="hljs-string">'Label'</span>],axis=<span class="hljs-number">1</span>).drop_duplicates()
xx = pca.transform(ss.transform(xx.values))
p = clf.predict(xx)
np.unique(p,return_counts=<span class="hljs-literal">True</span>) 
</code></pre></div>
<div><pre class="hljs"><code>(<span class="hljs-name">array</span>([<span class="hljs-name">0</span>, <span class="hljs-number">1</span>]), array([ <span class="hljs-number">3</span>, <span class="hljs-number">65</span>])) </code></pre></div>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Towards creating an Intrusion Detection system]]></title>
            <guid>e9d0322825314bed8df57247b81ea8e4</guid>
            <pubDate>Fri, 17 Jun 2022 14:57:28 GMT</pubDate>
            <content:encoded><![CDATA[<p><img src="/_resources/8d1c85810b6f4a30a0933067795c36a3.jpg" />
&gt; <em>source: Getty images</em></p>
<h2 id="table-of-contents"><strong>Table of Contents</strong></h2>
<ul>
<li><a title="#abstract" href="#abstract">Abstract</a></li>
<li><a title="#introduction" href="#introduction">Introduction</a></li>
<li><a title="#objectives" href="#objectives">Objectives</a></li>
<li><a title="#problem-statement" href="#problem-statement">Problem Statement</a></li>
<li><a title="#literature-review" href="#literature-review">Literature review</a></li>
<li><a title="#methodology" href="#methodology">Methodology</a></li>
<li><a title="#conclusion" href="#conclusion">Conclusion</a></li>
<li><a title="#references" href="#references">References</a></li>
</ul>
<h2 id="abstract"><strong>Abstract</strong></h2>
<p>Intrusions in network refers to all those anomalous/undesirable activities that affects the CIA’s of the security for the intention of stealing, altering data and system that serves the desire of the attacker of bringing the service down. With our heavy dependence over internet technologies, we are living in the age of inter networked digital life but along with such advancements we’re are at a constant risk in terms of security and our privacy. The attacks include DoS, DDoS, Phishing and many more, they are varied and are always changing and more sophisticated. Still at present day DoS has been a major issue for big companies serving their business online. We at our defense side must be smart enough and deal with changing patterns and detect them as early as possible.</p>
<p>This article tries to introduced machine learning approach on detecting those intrusive patterns, taking data-set reference from CICIDS2017. Where we first capture the network traffic flow in the form of .pcap files, then process it into a well structured format of data using CIC-flow-meter. We try to infer the patterns that separates benign from intrusive ones. From the analysis, it is obtained that machine learning approaches could be one of the layer for security purpose rather than supplementing signature based IDS wholly.</p>
<p>Keywords: IDS(Intrusion Detection System), IPS(Intrusion Prevention System), FP(False Positive), FN(False Negative), Benign, Intrusions,Nftables</p>
<h2 id="introduction"><strong>Introduction</strong></h2>
<p>Using rule based system to analyze the network flow and detect the anomalies/intrusions based on their signatures stored on the database only isn’t an effective way to detect the network intrusions early for new type of intrusions that the database doesn’t consists of. We are living in the digital age where our entire business today is heavily dependent on. While having perks, we also have risks associated with it such as DoS, DDoS, Botnet, etc and many undiscovered attacks. So we want to realize such a system which learns patterns from network flows and discriminate them as desired. For that purpose we build a machine learning model based on CICIDS2017 and use a flowmeter to listen and dump packets into structured form. Then for training purpose utilize <a title="https://imbalanced-learn.org" href="https://imbalanced-learn.org">smote</a> to balance the imblanced datset then apply pca for dimension reduction and finally use random forest classifier to create a model from these data. After inferring the model with testing data we achieved a astonishing result that implies that is can classify the unseen network flows consisting of benign and intrusive network flows pretty well. This brings us to implementing such a system which now can create firewall rules based on these predictions in order to block them from harming the system. It utilizes the batch processing of each captured flow and outputs the corresponding predictions.</p>
<h2 id="objectives"><strong>Objectives</strong></h2>
<ol>
<li>Apply Machine learning approach to build an intrusion detection system</li>
</ol>
<h2 id="problem-statement"><strong>Problem statement</strong></h2>
<p>We are heavily dependent on internet based services, with rise of digital networking we are benefited as well as are in a risk of network based attacks.The network based attacks are costly for an organization and for individuals in terms of data, privacy and service. Previously used signature based method are though simple and direct in architecture, they need to maintain huge datasets, such isn’t possible to include all attack patterns till date, also new day attack type detection isn’t possible at all until network flow verified as an attack and updated to the signature database. We require an intelligent agent that learns what is actually benign network flow, we want it to detect the flows that deviate from this profile and mark it as intrusive/suspicious as early as possible.</p>
<h2 id="literature-review"><strong>Literature Review</strong></h2>
<p>For the purpose of intrusion detection we need to create a baseline about what is traffic is normal and what is not. Further we require such a  dataset which can represent the knowledge about the feature (domain knowledge) which is valuable for the study. Searching for those datasets bring us to KDD99Cup, NSL KDD, DEFCON-8, CICIDS2017, etc. Selecting from those didn;t pose such a challenege because we want such dataset that is most recent and has data entries that captures the new types of attacks. So, for the study analysis CICIDS2017 was chosen. This dataset consisted of about 80% benign and 20% different types of attack types. The original creators <a title="#references" href="#references">[4]</a> of the dataset used random forest regressor and weighted average method for feature selection whereas some authors <a title="#references" href="#references">[5]</a> used principal component analysis for dimensionality reduction.</p>
<h2 id="methodology"><strong>Methodology</strong><a type="application/zip" href="/_resources/1df4da8c03be4fb78ecaf6e671bd877b.zip"></a></h2>
<p>The methodology follows a ml workflow where Principal Component Analysis and Random Forest Classifier are used. The following link forwards to the implementation code. The dataset was downloaded from <a title="https://www.unb.ca/cic/datasets/ids-2017.html" href="https://www.unb.ca/cic/datasets/ids-2017.html">CICIDS2017</a> website, which was processed into parquet file for fast reading of the data entries.
<a href="/article/intrusion-detection(binary-classification)-with-pca-and-randomforest">Intrusion detection(Binary classification) with PCA and RandomForest</a></p>
<p>For implementing IPS, we design the system in such a way where each classified flows are then prevented by creating firewall rules using net-filter nftables in Linux based operating system by automated creation of nftables block rules in input, output or forward chain. Moreover, generating what kind of rule for the each flows is more of a concern.</p>
<h2 id="conclusion"><strong>Conclusion</strong></h2>
<p>From the above analysis, we could create a logically modeled solution for separating benign patterns apart from the intrusive ones based on the features extracted from the captured network packets using flow meter.</p>
<p>We could see that only applying principal component analysis setting components to be 10 such that knowledge from data doesn’t diminish for the purpose of dimentionality reduction and applying random forest classification algorithm such that the hyperparameteres used from cross validated high scoring model, we could obtain F1 score to be nearly 0.99 and roc auc to be 0.98. It shows the model learns the hidden patterns from data and is distinct on what separates benign from intrusion.</p>
<p>The study doesn’t end here rather with this kind of approach, it raises a question on what if we study on more set of features, what features have a value in determining the result.</p>
<p>Further, this study relies on flow-meter and its data structuring and its captured bidirectional flow. The input provided to the model act as an independent flow, but sophisticated attacks are sometimes made up of connected flows, it will create an ambiguity when same connection is sometime benign and anomalous.</p>
<p>While creating an IPS, the major factors we consider are False Positives and False Negatives. Both high FP and FN are unwanted but can be handled as per the purpose. This raises another intuition behind using this type of model along with other types of IDS. Controlling Benign as intrusions (FN) and intrusions as benign (FP) can be pretty straight forward if one applies manual setting for preventing mislabeling of benign as intrusion for networks with low traffic but still using them in large scale and creating manual rules to revert predictions is still not an efficient way.</p>
<p>In further analysis we will see what other methods we can focus on getting features that are valuable using CNN and neural networks and also study what kind of IPS needs to be built for such system. In following articles we will discuss the types of approach to achieve creating varied types of rules for different kinds of attacks and block types such as specific port or ip block or entire network block . Such implementation will be targeted for network layer and for IPv4 networks only and also we will discuss the efficiency required for such system for processing huge network traffic for classifying them as Benign or Intrusions.</p>
<p>The entire source code of this could be found at : <a title="https://github.com/azwyane/NGuard" href="https://github.com/azwyane/NGuard"><em>https://github.com/azwyane/NGuard</em></a></p>
<h2 id="references"><strong>References</strong></h2>
<ol>
<li>
<p><em><a title="https://www.unb.ca/cic/research/applications.html" href="https://www.unb.ca/cic/research/applications.html">https://www.unb.ca/cic/research/applications.html</a></em></p>
</li>
<li>
<p><em><a title="http://www.unb.ca/cic/datasets/IDS2017.html" href="http://www.unb.ca/cic/datasets/IDS2017.html">http://www.unb.ca/cic/datasets/IDS2017.html</a></em></p>
</li>
<li>
<p><em><a title="https://wiki.nftables.org/wiki-nftables/index.php/Main_Page" href="https://wiki.nftables.org/wiki-nftables/index.php/Main_Page">https://wiki.nftables.org/wiki-nftables/index.php/Main_Page</a></em></p>
</li>
<li>
<p><em>I. Sharafaldin, A. H. Lashkari, and A. A. Ghorbani, “Toward generating a new intrusion detection dataset and intrusion traffic characterization,” in ICISSP 2018 - Proceedings of the 4th International Conference on Information Systems Security and Privacy, 2018,vol.2018-January,pp.108–116.doi:10.5220/0006639801080116.</em></p>
</li>
<li>
<p><em>R. Abdulhammed, H. Musafer, A. Alessa, M. Faezipour, and A. Abuzneid, “Features dimensionality reduction approaches for machine learning based network intrusion detection,” Electronics (Switzerland), vol. 8, no. 3, Mar. 2019, doi:10.3390/electronics8030322.</em></p>
</li>
</ol>
]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Beginning]]></title>
            <guid>9039f9c9c2e84652a9e66e1ce38b94e2</guid>
            <pubDate>Tue, 14 Jun 2022 14:19:48 GMT</pubDate>
            <content:encoded><![CDATA[<blockquote>
<p>Writing is a tough challenge</p>
</blockquote>
<p>So, finally I am pushing myself for the exploration of writing world, I always had a dream when finally I would sit down and pour my knowledge digitally.</p>
<p>Had just played around with webDav and I found Joplin, I couldn’t love more …</p>
<p>Set up my GitHub pages and I am ready to fire.</p>
<p>Here I come…</p>
]]></content:encoded>
        </item>
    </channel>
</rss>