<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta http-equiv="X-UA-Compatible" content="ie=edge" />
<link rel="stylesheet" href="/_assets/main.css" />

    <title>Intro GANs (week 1) - ..</title>
  <link rel="stylesheet" href="/_markdown_plugin_assets/katex/katex.css" />
<link rel="stylesheet" href="/_markdown_plugin_assets/highlight.js/atom-one-light.css" /></head>
  <body>
    <div class="main">
      <nav class="navigation">
        <a href="/">..</a>
      </nav>
      <article>
        <header>
          <h1 class="article-title">Intro GANs (week 1)</h1>
          <div class="article-info">
            <div>
              <span
                >Created At：<time datetime="1659589183913"
                  >2022-08-04 10:44</time
                ></span
              >
              <span
                >Updated At：<time datetime="1659942038394"
                  >2022-08-08 12:45</time
                ></span
              >
            </div>
            
          </div>
        </header>
        <div class="article-content markdown-body"><h1 id="generative-adversarial-network">Generative Adversarial Network</h1>
<p>(This is a note that I took while learning from this <a title="https://www.coursera.org/learn/build-basic-generative-adversarial-networks-gans/home/welcome" href="https://www.coursera.org/learn/build-basic-generative-adversarial-networks-gans/home/welcome">course</a> )</p>
<p><strong>Background requirements</strong>: Understanding of Deep learning</p>
<p><strong>Keyword</strong>: Generator and Discriminator, PyTorch</p>
<h2 id="generative-models">Generative models:</h2>
<p>Generative models are those  which take random input especially noise ξ and/or target Y to produce feature set(more specifically X)</p>
<p>Mathematically,</p>
<div><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>X</mi><mi mathvariant="normal">∣</mi><mi>ξ</mi><mo separator="true">,</mo><mi>Y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(X|ξ ,Y)







</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.04601em">ξ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span><span class="mclose">)</span></span></span></span></span></div>
<div><pre class="hljs"><code>i.e probability distribution of <span class="hljs-keyword">X</span> given ξ, <span class="hljs-keyword">Y</span> or ξ,<span class="hljs-keyword">Y</span> -&gt; <span class="hljs-keyword">X</span>
</code></pre></div>
<p>Some examples of Generative models are: VAEs (Variational Autoencoders), GANs(Generative Adversial Network)</p>
<img src="/_resources/382395037c674425b6c8e56d070cb473.png" alt="3544c4a84364cbdd24d13c78c04b548e.png" width="320" height="137" class="jop-noMdConv" />
<p>examples: VAEs, GANs</p>
<h2 id="variation-autoencoders">Variation autoencoders</h2>
<img src="/_resources/4f891b9c2937486e8f28106d34187274.png" alt="0068c5e1a58aa799278316a3a3aa4615.png" width="229" height="155" class="jop-noMdConv" />
<h2 id="gans">GANs</h2>
<img src="/_resources/5927dd5bfab1460f90e8aa7304874b26.png" alt="0f5ae5afbf8192b120b98f64d2b440b9.png" width="234" height="158" class="jop-noMdConv" />
<h2 id="cool-applications-of-gans">Cool applications of GANs:</h2>
<ul>
<li>style GAN2 (neural style transfer)</li>
<li>image translation</li>
<li>style transform</li>
<li>GauGan (translate rough sketch to picture)</li>
<li>Convert image to video(<a title="https://https//arxiv.org/pdf/1808.07371.pdf" href="https://https//arxiv.org/pdf/1808.07371.pdf">everybody dance now</a>)</li>
<li>3D GAN (design)</li>
<li>Data augmentation (producing new image data)</li>
<li>Image filters(Face filters)</li>
<li>Image super resolutions</li>
</ul>
<h3 id="goals">Goals:</h3>
<p>Generator learns to fool whereas discriminator learns to distinguish real from fake, at end fakes look real.</p>
<h3 id="discriminative-models">Discriminative models:</h3>
<p>Discriminative models are similar to classifier models which takes features as an input X and generate prediction of class Y. More specifically, given output feature generated from generator determine how much fake the feature set is for that target.</p>
<p>Mathematically,</p>
<div><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(Y|X)



</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mclose">)</span></span></span></span></span></div>
<div><pre class="hljs"><code>determine fakeness <span class="hljs-keyword">of</span> <span class="hljs-keyword">the</span> feature <span class="hljs-built_in">set</span> <span class="hljs-keyword">for</span> <span class="hljs-keyword">the</span> specified traget
</code></pre></div>
<img src="/_resources/914158c4bda345718a0b26e843d551f7.png" alt="2eb113ec48eb2b1bc7c110ca5362d8ec.png" width="287" height="149" class="jop-noMdConv" />
<h3 id="bce-cost-functionbinary-cross-entropy">BCE cost function(Binary cross entropy)</h3>
<p><img src="/_resources/ed4a681f48804bf8bce59b0c041fba23.png" alt="b6f19d967ba99db4b037221bddcfc8d5.png" width="526" height="116" class="jop-noMdConv" /> <img src="/_resources/e7aefef98625480d8c690c10edf3e421.png" alt="d93addf449f960e8b8676bb1ce82f076.png" width="518" height="143" class="jop-noMdConv" /></p>
<h2 id="gan-model">GAN model</h2>
<img src="/_resources/7665df088c1f436089118d27c1643da6.png" alt="87b286af863d0478be08cab5c1e1dc02.png" width="443" height="196" class="jop-noMdConv" />
<p>Generator and discriminator learn one at a time.(make both model  skill comparable, if one is more better than another, it affects)</p>
<h3 id="pytorch">PyTorch</h3>
<img src="/_resources/e49f8782ecde4d77a44c0ccf12c2fb18.png" alt="ee56a00e2db8cea1616ec3e703f3b866.png" width="483" height="238" class="jop-noMdConv" />
<div><pre class="hljs"><code><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-keyword">class</span> <span class="hljs-title class_">LogisticRegression</span>(nn.Module):
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,<span class="hljs-keyword">in</span></span>):
    <span class="hljs-built_in">super</span>().init()
    self.log_reg = nn.Sequential(nn.Linear(<span class="hljs-keyword">in</span>,<span class="hljs-number">1</span>),nn.sigmoid())
  
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):
    <span class="hljs-keyword">return</span> self.log_reg(x)
    
model = LogisticRegression(<span class="hljs-number">16</span>)
citerion = nn.BCELoss() <span class="hljs-comment">#cost function</span>
optimizer = torch.optim.SGD(model.parameters(),lr=<span class="hljs-number">0.01</span>)

<span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_epochs):
  y_hat = model(x)
  loss = criterion(y_hat,y)
  optimizer.zero_grad()
  loss.backward()
  optimizer.step()</code></pre></div>
<h3 id="references">References:</h3>
<p>1. <a title="https://colab.research.google.com/github/https-deeplearning-ai/GANs-Public/blob/master/C1W1_%28Colab%29_Pre_trained_model_exploration.ipynb" href="https://colab.research.google.com/github/https-deeplearning-ai/GANs-Public/blob/master/C1W1_%28Colab%29_Pre_trained_model_exploration.ipynb">https://colab.research.google.com/github/https-deeplearning-ai/GANs-Public/blob/master/C1W1_(Colab)_Pre_trained_model_exploration.ipynb</a></p>
<p>2. image credits to: <a title="https://www.coursera.org/learn/build-basic-generative-adversarial-networks-gans/home/welcome" href="https://www.coursera.org/learn/build-basic-generative-adversarial-networks-gans/home/welcome">deeplearning.ai</a></p>
<p>3. music VAE: <a title="https://www.youtube.com/watch?v=G5JT16flZwM" href="https://www.youtube.com/watch?v=G5JT16flZwM">https://www.youtube.com/watch?v=G5JT16flZwM</a></p>
<h3 id="notes">Notes:</h3>
<blockquote>
<h2 id="noise-vector">Noise vector</h2>
<p>The noise vector has the important role of making sure the images generated from the same class don’t all look the same.</p>
<p>In reality, is usually larger than just 1 value to allow for more combinations of what could be. There’s no special number that determines what works, but 100 is standard. Some researchers might use a power of 2, like 128 or 512(t<em>his is also called a spherical normal and denoted ~ where the represents the identity matrix and means the variance is 1 in all dimensions.)</em></p>
<h2 id="truncation-trick">Truncation trick</h2>
<p>The truncation trick as a way of trading off fidelity (quality) and diversity in the samples. It works like this: when you randomly sample your noise vector , you can choose to keep that random or you can sample another one.</p>
<p>Why would you want to sample another one?</p>
<p>Well, since I’m sampling from a normal distribution, my model will see more of those values within a standard deviation from the mean than those at the tails of the distribution—and this happens during training. This means that while the model is training, it’s likely to be familiar with certain noise vectors and as a result model those areas coming from familiar noise vector regions. In these areas, my model will likely have much more realistic results, but nothing too funky, it’s not taking as many risks in those regions mapped from those familiar noise vectors. This is the trade-off between fidelity (realistic, high quality images) and diversity (variety in images).</p>
<p><em><img src="/_resources/3e9659f40f7a4e708a0476b4644575d4.png" alt="truncated normal distribution" width="400" class="jop-noMdConv" /></em></p>
<blockquote>
<p><em>Image Credit: Modelica</em></p>
</blockquote>
<p>What the truncation trick does is resamples the noise vector until it falls within some bounds of the normal distribution. In fact, it samples from a truncated normal distribution where the tails are cut off at different values (red line in graph is truncated normal, blue is original). You can tune these values and thus tune fidelity/diversity. Recall that having a lot of fidelity is not always the goal—one failure mode of that is that you get one really real image but nothing else (no diversity), and that’s not very interesting or successful from a model that’s supposed to model the realm of all possible human faces or that of all possible coconuts—including that of a cat pouncing after a flying coconut (but with extremely low probability).</p>
<p><a title="https://colab.research.google.com/github/https-deeplearning-ai/GANs-Public/blob/master/C1W1_%28Colab%29_Inputs_to_a_pre_trained_GAN.ipynb" href="https://colab.research.google.com/github/https-deeplearning-ai/GANs-Public/blob/master/C1W1_%28Colab%29_Inputs_to_a_pre_trained_GAN.ipynb">@ credit: https://colab.research.google.com/github/https-deeplearning-ai/GANs-Public/blob/master/C1W1_(Colab)_Inputs_to_a_pre_trained_GAN.ipynb</a></p>
</blockquote>
</div>
      </article>
    </div>
  </body>
</html>
